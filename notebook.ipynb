{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "import torch\n",
    "\n",
    "from sem2SQL import transform\n",
    "from src import args as arg\n",
    "from src import utils\n",
    "from src.models.model import IRNet\n",
    "from src.rule import semQL\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from dummy_input import DUMMY_INPUT\n",
    "from src.rule.sem_utils import alter_column0, alter_inter, alter_not_in\n",
    "from src.utils import load_data_new\n",
    "\n",
    "MODEL_PATH = \"./saved_model/IRNet_pretrained.model\"\n",
    "EMBEDS_PATH = \"./data/glove.42B.300d.txt\"\n",
    "QUESTION_DATA_PATH = \"./data/custom/question.json\"\n",
    "TABLE_DATA_PATH = \"./data/custom/tables.json\"\n",
    "PREDICT_LF_PATH = \"./data/custom/predict_lf.json\"\n",
    "\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_parser = arg.init_arg_parser()\n",
    "args = arg_parser.parse_args(\"--dataset ./data/custom --glove_embed_path ./data/glove.42B.300d.txt --cuda --epoch 50 --loss_epoch_threshold 50 --sketch_loss_coefficie 1.0 --beam_size 5 --seed 90 --save ${save_name} --embed_size 300 --sentence_features --column_pointer --hidden_size 300 --lr_scheduler --lr_scheduler_gammar 0.5 --att_vec_size 300 --load_model ./saved_model/IRNet_pretrained.model\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Column Pointer:  True\n",
      "load pretrained model from ./saved_model/IRNet_pretrained.model\n",
      "Loading word embedding from ./data/glove.42B.300d.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IRNet(\n",
       "  (encoder_lstm): LSTM(300, 150, batch_first=True, bidirectional=True)\n",
       "  (lf_decoder_lstm): LSTMCell(556, 300)\n",
       "  (sketch_decoder_lstm): LSTMCell(556, 300)\n",
       "  (decoder_cell_init): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (att_sketch_linear): Linear(in_features=300, out_features=300, bias=False)\n",
       "  (att_lf_linear): Linear(in_features=300, out_features=300, bias=False)\n",
       "  (sketch_att_vec_linear): Linear(in_features=600, out_features=300, bias=False)\n",
       "  (lf_att_vec_linear): Linear(in_features=600, out_features=300, bias=False)\n",
       "  (prob_att): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (prob_len): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (col_type): Linear(in_features=4, out_features=300, bias=True)\n",
       "  (sketch_encoder): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (production_embed): Embedding(46, 128)\n",
       "  (type_embed): Embedding(10, 128)\n",
       "  (att_project): Linear(in_features=428, out_features=300, bias=True)\n",
       "  (N_embed): Embedding(5, 128)\n",
       "  (query_vec_to_action_embed): Linear(in_features=300, out_features=128, bias=False)\n",
       "  (q_att): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (column_rnn_input): Linear(in_features=300, out_features=128, bias=False)\n",
       "  (table_rnn_input): Linear(in_features=300, out_features=128, bias=False)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (column_pointer_net): PointerNet(\n",
       "    (src_encoding_linear): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (input_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (type_linear): Linear(in_features=32, out_features=300, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (context_linear): Conv1d(300, 300, kernel_size=(1,), stride=(1,))\n",
       "    (coverage_linear): Conv1d(1, 300, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (table_pointer_net): PointerNet(\n",
       "    (src_encoding_linear): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (input_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (type_linear): Linear(in_features=32, out_features=300, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (context_linear): Conv1d(300, 300, kernel_size=(1,), stride=(1,))\n",
       "    (coverage_linear): Conv1d(1, 300, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = semQL.Grammar()\n",
    "model = IRNet(args, grammar)\n",
    "\n",
    "if CUDA: model.cuda()\n",
    "\n",
    "print('load pretrained model from %s' % MODEL_PATH)\n",
    "pretrained_model = torch.load(MODEL_PATH,\n",
    "                              map_location=lambda storage, loc: storage)\n",
    "import copy\n",
    "pretrained_modeled = copy.deepcopy(pretrained_model)\n",
    "for k in pretrained_model.keys():\n",
    "    if k not in model.state_dict().keys():\n",
    "        del pretrained_modeled[k]\n",
    "\n",
    "model.load_state_dict(pretrained_modeled)\n",
    "\n",
    "model.word_emb = utils.load_word_emb(EMBEDS_PATH)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_str = \"How many customers do we have?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./data/custom/tables.json\n"
     ]
    }
   ],
   "source": [
    "DUMMY_INPUT[\"question\"] = question_str\n",
    "DUMMY_INPUT[\"question_toks\"] = question_str.split(\" \")\n",
    "\n",
    "import json\n",
    "with open(QUESTION_DATA_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump([DUMMY_INPUT], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "subprocess.run([\"cd preprocess && bash run_me.sh ../data/custom/question.json ../data/custom/tables.json\"], shell=True)\n",
    "\n",
    "with open(TABLE_DATA_PATH) as inf:\n",
    "    print(\"Loading data from %s\" % TABLE_DATA_PATH)\n",
    "    table_data = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./data/custom/question.json\n"
     ]
    }
   ],
   "source": [
    "question_data, table_data_new = load_data_new(QUESTION_DATA_PATH, table_data, use_small=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'db_id': 'customer',\n",
       "  'query': 'SELECT count(*) FROM customer',\n",
       "  'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'customer'],\n",
       "  'query_toks_no_value': ['select',\n",
       "   'count',\n",
       "   '(',\n",
       "   '*',\n",
       "   ')',\n",
       "   'from',\n",
       "   'customer'],\n",
       "  'question': 'How many customers do we have?',\n",
       "  'question_toks': ['how', 'many', 'customer', 'do', 'we', 'have?'],\n",
       "  'sql': {'except': None,\n",
       "   'from': {'conds': [], 'table_units': [['table_unit', 0]]},\n",
       "   'groupby': [],\n",
       "   'having': [],\n",
       "   'intersect': None,\n",
       "   'limit': None,\n",
       "   'orderby': [],\n",
       "   'select': [False, [[3, [0, [0, 0, False], None]]]],\n",
       "   'union': None,\n",
       "   'where': []},\n",
       "  'names': ['*',\n",
       "   'customer_Id',\n",
       "   'name',\n",
       "   'address',\n",
       "   'birthday',\n",
       "   'phone',\n",
       "   'city'],\n",
       "  'table_names': ['customer'],\n",
       "  'col_set': ['*',\n",
       "   'customer_Id',\n",
       "   'name',\n",
       "   'address',\n",
       "   'birthday',\n",
       "   'phone',\n",
       "   'city'],\n",
       "  'col_table': [-1, 0, 0, 0, 0, 0, 0],\n",
       "  'keys': {'1': 1},\n",
       "  'origin_question_toks': ['How', 'many', 'customers', 'do', 'we', 'have?'],\n",
       "  'question_arg': [['how'], ['many'], ['customer'], ['do'], ['we'], ['have?']],\n",
       "  'question_arg_type': [['NONE'],\n",
       "   ['NONE'],\n",
       "   ['table'],\n",
       "   ['NONE'],\n",
       "   ['NONE'],\n",
       "   ['NONE']],\n",
       "  'nltk_pos': [['how', 'WRB'],\n",
       "   ['many', 'JJ'],\n",
       "   ['customer', 'NN'],\n",
       "   ['do', 'VBP'],\n",
       "   ['we', 'PRP'],\n",
       "   ['have?', 'VB']],\n",
       "  'rule_label': 'Root1(3) Root(5) Sel(0) N(0) A(3) C(0) T(0)'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer': {'column_names': [[-1, '*'],\n",
       "   [0, 'customer_Id'],\n",
       "   [0, 'name'],\n",
       "   [0, 'address'],\n",
       "   [0, 'birthday'],\n",
       "   [0, 'phone'],\n",
       "   [0, 'city']],\n",
       "  'column_names_original': [[-1, '*'],\n",
       "   [0, 'customer_ID'],\n",
       "   [0, 'name'],\n",
       "   [0, 'address'],\n",
       "   [0, 'birthday'],\n",
       "   [0, 'phone'],\n",
       "   [0, 'city']],\n",
       "  'column_types': ['text', 'number', 'text', 'text', 'text', 'number', 'text'],\n",
       "  'db_id': 'customer',\n",
       "  'foreign_keys': [],\n",
       "  'primary_keys': [1],\n",
       "  'table_names': ['customer'],\n",
       "  'table_names_original': ['customer']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c46dc670528a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_datas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_data_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/jna/Documents/github/IRNet/src/utils.py\u001b[0m in \u001b[0;36mget_json_data\u001b[0;34m(model, table_data, question, beam_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_batch_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mresults_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mlist_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jna/Documents/github/IRNet/src/models/model.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, examples, beam_size)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0msrc_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_sents_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0msrc_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jna/Documents/github/IRNet/src/models/basic_model.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, src_sents_var, src_sents_len, q_onehot_project)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mlast_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cell\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0msrc_token_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_x_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sents_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq_onehot_project\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jna/Documents/github/IRNet/src/models/basic_model.py\u001b[0m in \u001b[0;36mgen_x_batch\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mval_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_emb_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mval_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval_inp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nl2sql/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/miniconda3/envs/nl2sql/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "json_datas = utils.get_json_data(model, table_data_new, question_data, beam_size=args.beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
